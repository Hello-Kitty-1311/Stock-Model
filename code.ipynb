{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction System\n",
    "\n",
    "This notebook implements an advanced stock price prediction system using machine learning models including XGBoost ensemble and LSTM neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance xgboost tensorflow scikit-learn pandas numpy matplotlib plotly seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow available for LSTM models\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    LSTM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. LSTM model will be skipped.\")\n",
    "    LSTM_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data fetching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AAPL: possibly delisted; no price data found  (period=1y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for AAPL\n",
      "No data available for visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_valid_ticker():\n",
    "    while True:\n",
    "        stock = input(\"Enter a valid stock ticker (e.g., AAPL, TSLA, MSFT): \").upper()\n",
    "        try:\n",
    "            test = yf.Ticker(stock)\n",
    "            if test.history(period=\"1d\").empty:\n",
    "                print(\"Invalid ticker. Please try again.\")\n",
    "            else:\n",
    "                return stock\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating ticker: {e}\")\n",
    "            print(\"Invalid input. Please try again.\")\n",
    "\n",
    "def get_model_choice():\n",
    "    print(\"\\nChoose prediction model:\")\n",
    "    print(\"1. XGBoost (Less time, High accuracy)\")\n",
    "    print(\"2. LSTM (More time, Most accuracy)\")\n",
    "    print(\"3. Both (Conclusion with both models)\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (1/2/3): \")\n",
    "        if choice in ['1', '2', '3']:\n",
    "            return int(choice)\n",
    "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "def fetch_stock_data(ticker_symbol, period=\"max\"):\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    data = ticker.history(period=period)\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"No data found for {ticker_symbol}\")\n",
    "        return None\n",
    "\n",
    "    info = ticker.info\n",
    "    company_name = info.get('longName', ticker_symbol)\n",
    "\n",
    "    print(f\"\\nFetched data for {company_name} ({ticker_symbol})\")\n",
    "    print(f\"Data range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "    print(f\"Total trading days: {len(data)}\")\n",
    "\n",
    "    return data, company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    macd_signal = macd.ewm(span=signal).mean()\n",
    "    macd_hist = macd - macd_signal\n",
    "    return macd, macd_signal, macd_hist\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "    rolling_mean = prices.rolling(window=window).mean()\n",
    "    rolling_std = prices.rolling(window=window).std()\n",
    "    bb_upper = rolling_mean + (rolling_std * num_std)\n",
    "    bb_lower = rolling_mean - (rolling_std * num_std)\n",
    "    return bb_upper, rolling_mean, bb_lower\n",
    "\n",
    "def calculate_stochastic(high, low, close, k_window=14, d_window=3):\n",
    "    lowest_low = low.rolling(window=k_window).min()\n",
    "    highest_high = high.rolling(window=k_window).max()\n",
    "    stoch_k = 100 * ((close - lowest_low) / (highest_high - lowest_low))\n",
    "    stoch_d = stoch_k.rolling(window=d_window).mean()\n",
    "    return stoch_k, stoch_d\n",
    "\n",
    "def calculate_atr(high, low, close, window=14):\n",
    "    tr1 = high - low\n",
    "    tr2 = abs(high - close.shift())\n",
    "    tr3 = abs(low - close.shift())\n",
    "    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    atr = true_range.rolling(window=window).mean()\n",
    "    return atr\n",
    "\n",
    "def calculate_williams_r(high, low, close, window=14):\n",
    "    highest_high = high.rolling(window=window).max()\n",
    "    lowest_low = low.rolling(window=window).min()\n",
    "    williams_r = -100 * ((highest_high - close) / (highest_high - lowest_low))\n",
    "    return williams_r\n",
    "\n",
    "def add_technical_indicators(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['High_Low_Pct'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['Open_Close_Pct'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    df['Price_Volume'] = df['Close'] * df['Volume']\n",
    "    df['Volume_Rate'] = df['Volume'] / df['Volume'].rolling(window=20).mean()\n",
    "\n",
    "    for period in [3, 5, 10, 20, 50, 100]:\n",
    "        df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()\n",
    "        df[f'MA_{period}_ratio'] = df['Close'] / df[f'MA_{period}']\n",
    "        df[f'EMA_{period}'] = df['Close'].ewm(span=period).mean()\n",
    "        df[f'EMA_{period}_ratio'] = df['Close'] / df[f'EMA_{period}']\n",
    "        df[f'Close_MA_{period}_diff'] = df['Close'] - df[f'MA_{period}']\n",
    "\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['RSI_7'] = calculate_rsi(df['Close'], 7)\n",
    "    df['RSI_21'] = calculate_rsi(df['Close'], 21)\n",
    "\n",
    "    df['MACD'], df['MACD_Signal'], df['MACD_Hist'] = calculate_macd(df['Close'])\n",
    "\n",
    "    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = calculate_bollinger_bands(df['Close'])\n",
    "    df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']\n",
    "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "\n",
    "    df['Stoch_K'], df['Stoch_D'] = calculate_stochastic(df['High'], df['Low'], df['Close'])\n",
    "    df['ATR'] = calculate_atr(df['High'], df['Low'], df['Close'])\n",
    "    df['Williams_R'] = calculate_williams_r(df['High'], df['Low'], df['Close'])\n",
    "\n",
    "    for period in [5, 10, 20]:\n",
    "        df[f'Vol_MA_{period}'] = df['Volume'].rolling(window=period).mean()\n",
    "        df[f'Vol_Std_{period}'] = df['Volume'].rolling(window=period).std()\n",
    "        df[f'Price_Volatility_{period}'] = df['Close'].rolling(window=period).std()\n",
    "        df[f'High_MA_{period}'] = df['High'].rolling(window=period).mean()\n",
    "        df[f'Low_MA_{period}'] = df['Low'].rolling(window=period).mean()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_features(data, target_col='Close', sequence_length=10):\n",
    "    df = data.copy()\n",
    "\n",
    "    price_cols = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    indicator_cols = ['RSI', 'MACD', 'BB_Position', 'Stoch_K', 'ATR']\n",
    "\n",
    "    for col in price_cols + indicator_cols:\n",
    "        if col in df.columns:\n",
    "            for i in range(1, sequence_length + 1):\n",
    "                df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
    "\n",
    "    for window in [3, 5, 10]:\n",
    "        df[f'{target_col}_momentum_{window}'] = df[target_col] / df[target_col].shift(window) - 1\n",
    "        df[f'{target_col}_volatility_{window}'] = df[target_col].rolling(window).std() / df[target_col].rolling(window).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "def prepare_features_xgboost(data, look_back=20, forecast_horizon=1):\n",
    "    df = data.copy()\n",
    "    df = create_sequence_features(df, sequence_length=look_back)\n",
    "\n",
    "    for i in range(1, forecast_horizon + 1):\n",
    "        df[f'Target_{i}'] = df['Close'].shift(-i)\n",
    "\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost ensemble model implementation\n",
    "\n",
    "def train_xgboost_model(data, forecast_horizon=1):\n",
    "    print(\"\\nTraining Enhanced XGBoost model...\")\n",
    "\n",
    "    target_cols = [f'Target_{i}' for i in range(1, forecast_horizon + 1)]\n",
    "    feature_cols = [col for col in data.columns if col not in target_cols + ['Open', 'Close', 'High', 'Low', 'Volume', 'Adj Close']]\n",
    "\n",
    "    X = data[feature_cols]\n",
    "    y = data[target_cols[0]] if len(target_cols) == 1 else data[target_cols]\n",
    "\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    split_ratio = 0.85\n",
    "    split_idx = int(len(X) * split_ratio)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.03,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_alpha=0.05,\n",
    "        reg_lambda=0.05,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    gb_model = GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    models = [('XGB', xgb_model), ('RF', rf_model), ('GB', gb_model)]\n",
    "\n",
    "    ensemble_train_pred = np.zeros(len(y_train))\n",
    "    ensemble_test_pred = np.zeros(len(y_test))\n",
    "\n",
    "    for name, model in models:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        train_pred = model.predict(X_train_scaled)\n",
    "        test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        ensemble_train_pred += train_pred / len(models)\n",
    "        ensemble_test_pred += test_pred / len(models)\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, ensemble_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, ensemble_test_pred))\n",
    "    train_r2 = r2_score(y_train, ensemble_train_pred)\n",
    "    test_r2 = r2_score(y_test, ensemble_test_pred)\n",
    "\n",
    "    print(f\"Ensemble Training RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"Ensemble Testing RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Ensemble Training R²: {train_r2:.4f}\")\n",
    "    print(f\"Ensemble Testing R²: {test_r2:.4f}\")\n",
    "\n",
    "    return models, X_test_scaled, y_test.values, ensemble_test_pred, split_idx, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model implementation\n",
    "\n",
    "def prepare_lstm_data(data, look_back=60, forecast_horizon=1):\n",
    "    features = ['Close', 'Volume', 'High', 'Low', 'Open']\n",
    "    if 'RSI' in data.columns:\n",
    "        features.append('RSI')\n",
    "    if 'MACD' in data.columns:\n",
    "        features.append('MACD')\n",
    "    if 'BB_Position' in data.columns:\n",
    "        features.append('BB_Position')\n",
    "\n",
    "    feature_data = data[features].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(feature_data)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(scaled_data) - forecast_horizon + 1):\n",
    "        X.append(scaled_data[i-look_back:i])\n",
    "        y.append(scaled_data[i:i+forecast_horizon, 0])\n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    if forecast_horizon == 1:\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "def train_lstm_model(data, forecast_horizon=1):\n",
    "    if not LSTM_AVAILABLE:\n",
    "        print(\"LSTM model not available. Skipping...\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    print(\"\\nTraining Enhanced LSTM model...\")\n",
    "\n",
    "    X, y, scaler = prepare_lstm_data(data, look_back=60, forecast_horizon=forecast_horizon)\n",
    "\n",
    "    split_ratio = 0.85\n",
    "    split_idx = int(len(X) * split_ratio)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        GRU(32, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(forecast_horizon if forecast_horizon > 1 else 1)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='huber',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=10, min_lr=0.00001)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=150,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    train_pred = model.predict(X_train, verbose=0)\n",
    "    test_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "    if forecast_horizon == 1:\n",
    "        train_pred = train_pred.flatten()\n",
    "        test_pred = test_pred.flatten()\n",
    "\n",
    "    train_pred_prices = scaler.inverse_transform(\n",
    "        np.column_stack([train_pred, np.zeros((len(train_pred), scaler.n_features_in_ - 1))])\n",
    "    )[:, 0]\n",
    "    test_pred_prices = scaler.inverse_transform(\n",
    "        np.column_stack([test_pred, np.zeros((len(test_pred), scaler.n_features_in_ - 1))])\n",
    "    )[:, 0]\n",
    "    y_train_prices = scaler.inverse_transform(\n",
    "        np.column_stack([y_train, np.zeros((len(y_train), scaler.n_features_in_ - 1))])\n",
    "    )[:, 0]\n",
    "    y_test_prices = scaler.inverse_transform(\n",
    "        np.column_stack([y_test, np.zeros((len(y_test), scaler.n_features_in_ - 1))])\n",
    "    )[:, 0]\n",
    "\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_prices, train_pred_prices))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_prices, test_pred_prices))\n",
    "    train_r2 = r2_score(y_train_prices, train_pred_prices)\n",
    "    test_r2 = r2_score(y_test_prices, test_pred_prices)\n",
    "\n",
    "    print(f\"LSTM Training RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"LSTM Testing RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"LSTM Training R²: {train_r2:.4f}\")\n",
    "    print(f\"LSTM Testing R²: {test_r2:.4f}\")\n",
    "\n",
    "    return model, X_test, y_test_prices, test_pred_prices, split_idx + 60, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading signals generation and recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trading_signals(original_data, predictions, start_idx):\n",
    "    df = original_data.copy()\n",
    "    df['Predicted'] = np.nan\n",
    "    df['Buy_Signal'] = False\n",
    "    df['Sell_Signal'] = False\n",
    "\n",
    "    if len(predictions) > 0:\n",
    "        end_idx = start_idx + len(predictions)\n",
    "        if end_idx <= len(df):\n",
    "            df.iloc[start_idx:end_idx, df.columns.get_loc('Predicted')] = predictions\n",
    "\n",
    "    if 'BB_Upper' not in df.columns:\n",
    "        df['BB_Upper'] = df['Close'].rolling(window=20).mean() + (df['Close'].rolling(window=20).std() * 2)\n",
    "        df['BB_Lower'] = df['Close'].rolling(window=20).mean() - (df['Close'].rolling(window=20).std() * 2)\n",
    "        df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "\n",
    "    df['Signal'] = 0\n",
    "\n",
    "    for i in range(max(1, start_idx), len(df)):\n",
    "        if pd.notna(df.iloc[i]['Predicted']):\n",
    "            current_price = df.iloc[i]['Close']\n",
    "            predicted_price = df.iloc[i]['Predicted']\n",
    "            bb_lower = df.iloc[i]['BB_Lower']\n",
    "            bb_upper = df.iloc[i]['BB_Upper']\n",
    "            rsi = df.iloc[i].get('RSI', 50)\n",
    "\n",
    "            price_change = (predicted_price - current_price) / current_price\n",
    "\n",
    "            if (current_price <= bb_lower * 1.01 and\n",
    "                predicted_price > current_price * 1.002 and\n",
    "                rsi < 45 and price_change > 0.005):\n",
    "                df.iloc[i, df.columns.get_loc('Buy_Signal')] = True\n",
    "                df.iloc[i, df.columns.get_loc('Signal')] = 1\n",
    "            elif (current_price >= bb_upper * 0.99 and\n",
    "                  predicted_price < current_price * 0.998 and\n",
    "                  rsi > 55 and price_change < -0.005):\n",
    "                df.iloc[i, df.columns.get_loc('Sell_Signal')] = True\n",
    "                df.iloc[i, df.columns.get_loc('Signal')] = -1\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_recommendation(data, current_price, predicted_price, rsi, bb_position):\n",
    "    signals = []\n",
    "\n",
    "    price_change = (predicted_price - current_price) / current_price\n",
    "    if price_change > 0.02:\n",
    "        signals.append(('buy', 0.4))\n",
    "    elif price_change < -0.02:\n",
    "        signals.append(('sell', 0.4))\n",
    "    else:\n",
    "        signals.append(('hold', 0.3))\n",
    "\n",
    "    if rsi < 30:\n",
    "        signals.append(('buy', 0.3))\n",
    "    elif rsi > 70:\n",
    "        signals.append(('sell', 0.3))\n",
    "    else:\n",
    "        signals.append(('hold', 0.2))\n",
    "\n",
    "    if bb_position < 0.2:\n",
    "        signals.append(('buy', 0.25))\n",
    "    elif bb_position > 0.8:\n",
    "        signals.append(('sell', 0.25))\n",
    "    else:\n",
    "        signals.append(('hold', 0.2))\n",
    "\n",
    "    buy_prob = sum([weight for action, weight in signals if action == 'buy'])\n",
    "    sell_prob = sum([weight for action, weight in signals if action == 'sell'])\n",
    "    hold_prob = sum([weight for action, weight in signals if action == 'hold'])\n",
    "\n",
    "    total = buy_prob + sell_prob + hold_prob\n",
    "    buy_prob = (buy_prob / total) * 100\n",
    "    sell_prob = (sell_prob / total) * 100\n",
    "    hold_prob = (hold_prob / total) * 100\n",
    "\n",
    "    return buy_prob, hold_prob, sell_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_plot(data_with_signals, company_name, ticker_symbol):\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=[f'{company_name} ({ticker_symbol}) - Price Prediction & Trading Signals', 'Volume'],\n",
    "        vertical_spacing=0.1,\n",
    "        row_heights=[0.7, 0.3]\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=data_with_signals.index, y=data_with_signals['Close'],\n",
    "                  name='Actual Price', line=dict(color='blue', width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    predicted_data = data_with_signals.dropna(subset=['Predicted'])\n",
    "    if not predicted_data.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=predicted_data.index, y=predicted_data['Predicted'],\n",
    "                      name='Predicted Price', line=dict(color='red', width=2, dash='dash')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    if 'BB_Upper' in data_with_signals.columns:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data_with_signals.index, y=data_with_signals['BB_Upper'],\n",
    "                      name='Upper Band', line=dict(color='gray', width=1), opacity=0.7),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=data_with_signals.index, y=data_with_signals['BB_Lower'],\n",
    "                      name='Lower Band', line=dict(color='gray', width=1), opacity=0.7,\n",
    "                      fill='tonexty', fillcolor='rgba(128,128,128,0.1)'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    buy_signals = data_with_signals[data_with_signals['Buy_Signal']]\n",
    "    if not buy_signals.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=buy_signals.index, y=buy_signals['Close'],\n",
    "                      mode='markers', name='Buy Signal',\n",
    "                      marker=dict(color='green', size=10, symbol='triangle-up')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    sell_signals = data_with_signals[data_with_signals['Sell_Signal']]\n",
    "    if not sell_signals.empty:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=sell_signals.index, y=sell_signals['Close'],\n",
    "                      mode='markers', name='Sell Signal',\n",
    "                      marker=dict(color='red', size=10, symbol='triangle-down')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=data_with_signals.index, y=data_with_signals['Volume'],\n",
    "               name='Volume', marker_color='rgba(0,100,80,0.6)'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'{company_name} ({ticker_symbol}) - Enhanced Stock Analysis Dashboard',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price ($)',\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(rangeslider_visible=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Prediction System initialized\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"=== Enhanced Stock Price Prediction System ===\")\n",
    "\n",
    "    stock_ticker = get_valid_ticker()\n",
    "    model_choice = get_model_choice()\n",
    "\n",
    "    result = fetch_stock_data(stock_ticker)\n",
    "    if result is None:\n",
    "        return\n",
    "\n",
    "    data, company_name = result\n",
    "    data_with_indicators = add_technical_indicators(data)\n",
    "\n",
    "    xgb_results = None\n",
    "    lstm_results = None\n",
    "\n",
    "    if model_choice in [1, 3]:\n",
    "        xgb_data = prepare_features_xgboost(data_with_indicators)\n",
    "        xgb_results = train_xgboost_model(xgb_data)\n",
    "\n",
    "    if model_choice in [2, 3] and LSTM_AVAILABLE:\n",
    "        lstm_results = train_lstm_model(data_with_indicators)\n",
    "\n",
    "    if model_choice == 1 and xgb_results[0] is not None:\n",
    "        models, X_test, y_test, predictions, split_idx, scaler = xgb_results\n",
    "        data_with_signals = generate_trading_signals(data_with_indicators, predictions, split_idx)\n",
    "        model_name = \"Enhanced Ensemble\"\n",
    "\n",
    "    elif model_choice == 2 and lstm_results[0] is not None:\n",
    "        model, X_test, y_test, predictions, split_idx, scaler = lstm_results\n",
    "        data_with_signals = generate_trading_signals(data_with_indicators, predictions, split_idx)\n",
    "        model_name = \"Enhanced LSTM\"\n",
    "\n",
    "    elif model_choice == 3:\n",
    "        if xgb_results[0] is not None and lstm_results[0] is not None:\n",
    "            xgb_pred = xgb_results[3]\n",
    "            lstm_pred = lstm_results[3]\n",
    "\n",
    "            min_len = min(len(xgb_pred), len(lstm_pred))\n",
    "            xgb_weight = 0.6\n",
    "            lstm_weight = 0.4\n",
    "            avg_predictions = (xgb_pred[:min_len] * xgb_weight + lstm_pred[:min_len] * lstm_weight)\n",
    "\n",
    "            split_idx = max(xgb_results[4], lstm_results[4])\n",
    "            data_with_signals = generate_trading_signals(data_with_indicators, avg_predictions, split_idx)\n",
    "            model_name = \"Combined Enhanced Models\"\n",
    "        else:\n",
    "            print(\"Both models not available. Using available model.\")\n",
    "            if xgb_results[0] is not None:\n",
    "                models, X_test, y_test, predictions, split_idx, scaler = xgb_results\n",
    "                data_with_signals = generate_trading_signals(data_with_indicators, predictions, split_idx)\n",
    "                model_name = \"Enhanced Ensemble\"\n",
    "            else:\n",
    "                return\n",
    "\n",
    "    current_price = data_with_signals['Close'].iloc[-1]\n",
    "    predicted_price = data_with_signals['Predicted'].iloc[-1] if pd.notna(data_with_signals['Predicted'].iloc[-1]) else current_price\n",
    "    current_rsi = data_with_indicators['RSI'].iloc[-1] if 'RSI' in data_with_indicators.columns else 50\n",
    "\n",
    "    if 'BB_Upper' in data_with_signals.columns and 'BB_Lower' in data_with_signals.columns:\n",
    "        bb_upper = data_with_signals['BB_Upper'].iloc[-1]\n",
    "        bb_lower = data_with_signals['BB_Lower'].iloc[-1]\n",
    "        bb_position = (current_price - bb_lower) / (bb_upper - bb_lower) if bb_upper != bb_lower else 0.5\n",
    "    else:\n",
    "        bb_position = 0.5\n",
    "\n",
    "    buy_prob, hold_prob, sell_prob = calculate_recommendation(\n",
    "        data_with_signals, current_price, predicted_price, current_rsi, bb_position\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {model_name} Model Results ===\")\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    print(f\"Predicted Next Price: ${predicted_price:.2f}\")\n",
    "    print(f\"Price Change: {((predicted_price - current_price) / current_price) * 100:.2f}%\")\n",
    "    print(f\"Current RSI: {current_rsi:.2f}\")\n",
    "\n",
    "    print(f\"\\n=== Trading Recommendation ===\")\n",
    "    print(f\"BUY Probability: {buy_prob:.1f}%\")\n",
    "    print(f\"HOLD Probability: {hold_prob:.1f}%\")\n",
    "    print(f\"SELL Probability: {sell_prob:.1f}%\")\n",
    "\n",
    "    if buy_prob > max(hold_prob, sell_prob):\n",
    "        main_rec = \"BUY\"\n",
    "    elif sell_prob > max(buy_prob, hold_prob):\n",
    "        main_rec = \"SELL\"\n",
    "    else:\n",
    "        main_rec = \"HOLD\"\n",
    "\n",
    "    print(f\"\\nMain Recommendation: {main_rec}\")\n",
    "\n",
    "    create_interactive_plot(data_with_signals, company_name, stock_ticker)\n",
    "\n",
    "    print(f\"\\nEnhanced Analysis complete! Interactive chart displayed above.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .ipynb to .pkl file convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall scipy -y\n",
    "\n",
    "!pip install scipy==1.11.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    LSTM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LSTM_AVAILABLE = False\n",
    "\n",
    "def get_valid_ticker():\n",
    "    while True:\n",
    "        stock = input(\"Enter a valid stock ticker (e.g., AAPL, TSLA, MSFT): \").upper()\n",
    "        try:\n",
    "            test = yf.Ticker(stock)\n",
    "            if test.history(period=\"1d\").empty:\n",
    "                print(\"Invalid ticker. Please try again.\")\n",
    "            else:\n",
    "                return stock\n",
    "        except Exception as e:\n",
    "            print(f\"Error validating ticker: {e}\")\n",
    "            print(\"Invalid input. Please try again.\")\n",
    "\n",
    "def get_model_choice():\n",
    "    print(\"\\nChoose model to train and save:\")\n",
    "    print(\"1. XGBoost Ensemble\")\n",
    "    print(\"2. LSTM\")\n",
    "    while True:\n",
    "        choice = input(\"Enter your choice (1/2): \")\n",
    "        if choice in ['1', '2']:\n",
    "            return int(choice)\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "def fetch_stock_data(ticker_symbol, period=\"max\"):\n",
    "    ticker = yf.Ticker(ticker_symbol)\n",
    "    data = ticker.history(period=period)\n",
    "    if data.empty:\n",
    "        return None\n",
    "    info = ticker.info\n",
    "    company_name = info.get('longName', ticker_symbol)\n",
    "    print(f\"\\nFetched data for {company_name} ({ticker_symbol})\")\n",
    "    return data, company_name\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    macd_signal = macd.ewm(span=signal).mean()\n",
    "    macd_hist = macd - macd_signal\n",
    "    return macd, macd_signal, macd_hist\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "    rolling_mean = prices.rolling(window=window).mean()\n",
    "    rolling_std = prices.rolling(window=window).std()\n",
    "    bb_upper = rolling_mean + (rolling_std * num_std)\n",
    "    bb_lower = rolling_mean - (rolling_std * num_std)\n",
    "    return bb_upper, rolling_mean, bb_lower\n",
    "\n",
    "def add_technical_indicators(data):\n",
    "    df = data.copy()\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    for period in [3, 5, 10, 20, 50, 100]:\n",
    "        df[f'MA_{period}'] = df['Close'].rolling(window=period).mean()\n",
    "        df[f'EMA_{period}'] = df['Close'].ewm(span=period).mean()\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['MACD'], _, _ = calculate_macd(df['Close'])\n",
    "    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = calculate_bollinger_bands(df['Close'])\n",
    "    df['BB_Position'] = (df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])\n",
    "    return df\n",
    "\n",
    "def create_sequence_features(data, sequence_length=10):\n",
    "    df = data.copy()\n",
    "    price_cols = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    indicator_cols = ['RSI', 'MACD', 'BB_Position']\n",
    "    for col in price_cols + indicator_cols:\n",
    "        if col in df.columns:\n",
    "            for i in range(1, sequence_length + 1):\n",
    "                df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
    "    return df\n",
    "\n",
    "def prepare_features_xgboost(data, look_back=20, forecast_horizon=1):\n",
    "    df = data.copy()\n",
    "    df = create_sequence_features(df, sequence_length=look_back)\n",
    "    for i in range(1, forecast_horizon + 1):\n",
    "        df[f'Target_{i}'] = df['Close'].shift(-i)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def train_xgboost_model(data, forecast_horizon=1):\n",
    "    print(\"\\nTraining Enhanced XGBoost model...\")\n",
    "    target_cols = [f'Target_{i}' for i in range(1, forecast_horizon + 1)]\n",
    "    feature_cols = [col for col in data.columns if col not in target_cols + ['Open', 'Close', 'High', 'Low', 'Volume', 'Adj Close']]\n",
    "    X = data[feature_cols].select_dtypes(include=[np.number]).fillna(data.mean())\n",
    "    y = data[target_cols[0]]\n",
    "    split_idx = int(len(X) * 0.85)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.03, subsample=0.9, colsample_bytree=0.9, reg_alpha=0.05, reg_lambda=0.05, random_state=42, n_jobs=-1)\n",
    "    rf_model = RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=200, max_depth=6, learning_rate=0.05, subsample=0.9, random_state=42)\n",
    "    models = [('XGB', xgb_model), ('RF', rf_model), ('GB', gb_model)]\n",
    "    for name, model in models:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "    return models, scaler, X_train_scaled.columns.tolist()\n",
    "\n",
    "def prepare_lstm_data(data, look_back=60, forecast_horizon=1):\n",
    "    features = ['Close', 'Volume', 'High', 'Low', 'Open', 'RSI', 'MACD', 'BB_Position']\n",
    "    feature_data = data[features].fillna(method='ffill').fillna(method='bfill')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(feature_data)\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(scaled_data) - forecast_horizon + 1):\n",
    "        X.append(scaled_data[i-look_back:i])\n",
    "        y.append(scaled_data[i:i+forecast_horizon, 0])\n",
    "    X, y = np.array(X), np.array(y).reshape(-1)\n",
    "    return X, y, scaler, features\n",
    "\n",
    "def train_lstm_model(data, forecast_horizon=1):\n",
    "    if not LSTM_AVAILABLE:\n",
    "        return None, None, None\n",
    "    print(\"\\nTraining Enhanced LSTM model...\")\n",
    "    X, y, scaler, features_list = prepare_lstm_data(data, look_back=60, forecast_horizon=forecast_horizon)\n",
    "    split_idx = int(len(X) * 0.85)\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    model = Sequential([LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])), Dropout(0.2), BatchNormalization(), LSTM(64, return_sequences=True), Dropout(0.2), BatchNormalization(), GRU(32), Dropout(0.2), Dense(64, activation='relu'), BatchNormalization(), Dropout(0.1), Dense(32, activation='relu'), Dense(1)])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber', metrics=['mae'])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=10, min_lr=1e-5)\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=150, validation_data=(X_test, y_test), callbacks=[early_stopping, reduce_lr], verbose=0)\n",
    "    return model, scaler, features_list\n",
    "\n",
    "def main():\n",
    "    print(\"=== Model Training and Saving Script ===\")\n",
    "    stock_ticker = get_valid_ticker()\n",
    "    model_choice = get_model_choice()\n",
    "    result = fetch_stock_data(stock_ticker)\n",
    "    if result is None: return\n",
    "    data, _ = result\n",
    "    data_with_indicators = add_technical_indicators(data)\n",
    "    if model_choice == 1:\n",
    "        xgb_data = prepare_features_xgboost(data_with_indicators)\n",
    "        trained_models, scaler, feature_list = train_xgboost_model(xgb_data)\n",
    "        artifacts = {'models': trained_models, 'scaler': scaler, 'feature_list': feature_list}\n",
    "        filename = f'xgb_ensemble_{stock_ticker}.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(artifacts, f)\n",
    "        print(f\"\\n XGBoost Ensemble model and artifacts saved to '{filename}'\")\n",
    "    elif model_choice == 2 and LSTM_AVAILABLE:\n",
    "        trained_model, scaler, feature_list = train_lstm_model(data_with_indicators)\n",
    "        if trained_model:\n",
    "            model_filename = f'lstm_model_{stock_ticker}.keras'\n",
    "            trained_model.save(model_filename)\n",
    "            print(f\"\\n LSTM model saved to '{model_filename}'\")\n",
    "            artifacts = {'scaler': scaler, 'feature_list': feature_list}\n",
    "            scaler_filename = f'lstm_artifacts_{stock_ticker}.pkl'\n",
    "            with open(scaler_filename, 'wb') as f:\n",
    "                pickle.dump(artifacts, f)\n",
    "            print(f\"LSTM scaler and feature list saved to '{scaler_filename}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
